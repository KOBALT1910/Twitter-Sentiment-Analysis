{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {'type': np.int8, 'clear_text': str,}\n",
    "path = 'C:/Users/user/sentiment/clear_binary_twitts.csv' #home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (path, sep=',', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unic_words(data):\n",
    "    \n",
    "    number = 0\n",
    "    dic = []\n",
    "    i = 0\n",
    "    for st in data:\n",
    "        for w in str(st).split():\n",
    "            if w not in dic:\n",
    "                dic.append(w)\n",
    "       \n",
    "    number = len(dic)\n",
    "    return number, dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот ноутбук можно смотреть только после ноутбука (MyModel) ! Далее будет попытка улучшить (считерить) начальную версию модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Схитрим? ~0.8 о_____О\n",
    "В предыдущей модели мы записывали в словарь только слова из train выборки. В голову приходят мысли, что в реальной бизнес-задаче\n",
    "у нас есть огромная база данных сообщений, в которой очень много слов. Что если мы будем иметь полную статистику о всех словах,\n",
    "используемых в речи. Тогда мы будем знать, какие слова нейтральные, а какие используются чаще в позитивных/негативных сообщениях.\n",
    "Чтобы имитировать такое \"предобучение\", попробуем обработать в словарь весь сет данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p.s. Предлагаю называть это имитацией предобученого словаря, а не допусканием дикого оверфита с:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, l = count_unic_words(df['clear_text']) # n ~ 85к вместо 81к"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic_words(n, l):\n",
    "      \n",
    "    nul1 = [int(0) for i in range(n)]\n",
    "    nul2 = [int(0) for i in range(n)]    \n",
    "    dic = {'word': l, 'pos': nul1, 'neg': nul2}\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = create_dic_words(n, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_used_train_words(dataframe, dic):\n",
    "    \n",
    "    i = -1\n",
    "    for index, row in dataframe.iterrows():\n",
    "        i += 1\n",
    "        \n",
    "        spisok = row['clear_text']\n",
    "        \n",
    "        for w in str(spisok).split():\n",
    "            if row['type'] == 1:\n",
    "                dic.get('pos')[l.index(w)] += 1\n",
    "            if row['type'] == -1:\n",
    "                dic.get('neg')[l.index(w)] += 1\n",
    "\n",
    "        if (i % 10000 == 0):\n",
    "            print('обработана ', i, 'строка из 204150: ', i/2041.5, ' %\\n')\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "обработана  0 строка из 204150:  0.0  %\n",
      "\n",
      "обработана  10000 строка из 204150:  4.898359049718344  %\n",
      "\n",
      "обработана  20000 строка из 204150:  9.796718099436688  %\n",
      "\n",
      "обработана  30000 строка из 204150:  14.695077149155033  %\n",
      "\n",
      "обработана  40000 строка из 204150:  19.593436198873377  %\n",
      "\n",
      "обработана  50000 строка из 204150:  24.49179524859172  %\n",
      "\n",
      "обработана  60000 строка из 204150:  29.390154298310065  %\n",
      "\n",
      "обработана  70000 строка из 204150:  34.28851334802841  %\n",
      "\n",
      "обработана  80000 строка из 204150:  39.186872397746754  %\n",
      "\n",
      "обработана  90000 строка из 204150:  44.0852314474651  %\n",
      "\n",
      "обработана  100000 строка из 204150:  48.98359049718344  %\n",
      "\n",
      "обработана  110000 строка из 204150:  53.88194954690179  %\n",
      "\n",
      "обработана  120000 строка из 204150:  58.78030859662013  %\n",
      "\n",
      "обработана  130000 строка из 204150:  63.678667646338475  %\n",
      "\n",
      "обработана  140000 строка из 204150:  68.57702669605682  %\n",
      "\n",
      "обработана  150000 строка из 204150:  73.47538574577517  %\n",
      "\n",
      "обработана  160000 строка из 204150:  78.37374479549351  %\n",
      "\n",
      "обработана  170000 строка из 204150:  83.27210384521186  %\n",
      "\n",
      "обработана  180000 строка из 204150:  88.1704628949302  %\n",
      "\n",
      "обработана  190000 строка из 204150:  93.06882194464855  %\n",
      "\n",
      "обработана  200000 строка из 204150:  97.96718099436688  %\n",
      "\n",
      "обработана  210000 строка из 204150:  102.86554004408524  %\n",
      "\n",
      "обработана  220000 строка из 204150:  107.76389909380357  %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dictionary_train_words = filling_used_train_words(df, dic) # здесь будет сбитые %, так как 100% - это около 220к вместо 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nul3 = [int(0) for i in range(n)]\n",
    "dictionary_train_words['value'] = nul3\n",
    "for k in range(n):\n",
    "    q = (dictionary_train_words['pos'][k] - dictionary_train_words['neg'][k])/(dictionary_train_words['pos'][k] + dictionary_train_words['neg'][k])\n",
    "    dictionary_train_words['value'][k] = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_predict(data, dic):\n",
    "    \n",
    "    data = data.tolist()\n",
    "    pred = [int(-1) for i in range(len(data))]\n",
    "    \n",
    "    for z in range(len(data)):\n",
    "        p = 0\n",
    "        for w in str(data[z]).split():\n",
    "            if w in l:\n",
    "                p += dic['value'][l.index(w)]\n",
    "        if p >= 0:\n",
    "            pred[z] = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model  0.7965526362193617\n"
     ]
    }
   ],
   "source": [
    "print('My model ', accuracy_score(test['type'], my_model_predict(test['clear_text'], dictionary_train_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу приходят мысли применить предобученные вектора слов последних публикаций 2018 года. Такие как, ELMO и BERT.\n",
    "Но, так как я ограничен размерами своей оперативной памятьи, попробовать это не могу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of resources with pretrained vectors:\n",
    "http://docs.deeppavlov.ai/en/master/intro/pretrained_vectors.html\n",
    "http://docs.deeppavlov.ai/en/master/components/classifiers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой ссылке есть вектора слов с твиттера - ELMo on Russian Twitter (8.5 Gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
